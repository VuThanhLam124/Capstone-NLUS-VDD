# Schema Linking for Text-to-SQL (TPC-DS)

## ğŸ¯ Overview

Há»‡ thá»‘ng Schema Linking káº¿t há»£p 3 ká»¹ thuáº­t state-of-the-art:

1. **Bidirectional Linking**: Questionâ†’Schema + Schemaâ†’Question
2. **Vector-based Retrieval**: Embedding similarity vá»›i BGE-M3
3. **Context Engineering**: Dynamic schema selection

## ğŸ“‹ Setup

```bash
# Install dependencies
pip install sentence-transformers rank-bm25

# Test schema linking
python research_pipeline/schema_linking.py
```

## ğŸš€ Usage

### 1. Generate Training Data vá»›i Schema Linking

```bash
# With schema linking (recommended)
python research_pipeline/generate_tpcds_training_data.py \
    --input research_pipeline/datasets/train_clean.csv \
    --output research_pipeline/datasets/train_tpcds_linked.jsonl

# Without schema linking (full schema)
python research_pipeline/generate_tpcds_training_data.py --no-linking
```

### 2. Benchmark vá»›i Schema Linking

```bash
# Enable schema linking
python research_pipeline/finetune_and_benchmark.py \
    --skip-train \
    --adapter Ellbendls/Qwen-3-4b-Text_to_SQL \
    --easy \
    --schema-linking \
    --few-shot 3 \
    --max-test-samples 10

# Compare: Full schema vs Schema linking
python research_pipeline/finetune_and_benchmark.py --skip-train --easy  # Full schema
python research_pipeline/finetune_and_benchmark.py --skip-train --easy --schema-linking  # Linked
```

### 3. Finetune trÃªn TPC-DS Data

```bash
# Step 1: Generate data
python research_pipeline/generate_tpcds_training_data.py

# Step 2: Train
python research_pipeline/finetune_and_benchmark.py \
    --train-data research_pipeline/datasets/train_tpcds_linked.jsonl \
    --adapter Ellbendls/Qwen-3-4b-Text_to_SQL \
    --output ./finetuned_tpcds \
    --epochs 3 \
    --batch-size 2 \
    --lr 2e-5

# Step 3: Evaluate
python research_pipeline/finetune_and_benchmark.py \
    --skip-train \
    --adapter ./finetuned_tpcds \
    --schema-linking \
    --easy
```

## ğŸ”¬ Ká»¹ Thuáº­t

### Bidirectional Linking

```python
from schema_linking import SchemaLinker

linker = SchemaLinker()
result = linker.link_schema("NÄƒm 2002 doanh thu bao nhiÃªu?")

print(result)
# {
#   'tables': ['store_sales', 'date_dim'],
#   'columns': ['ss_net_paid', 'd_year'],
#   'joins': ['JOIN date_dim ON ss_sold_date_sk = d_date_sk']
# }
```

### Dynamic Schema Generation

```python
# Instead of full 24 tables, only 3-5 relevant ones
schema = linker.build_dynamic_schema(
    "Sáº£n pháº©m bÃ¡n cháº¡y nháº¥t",
    max_tables=3
)
# Returns:
# TABLE store_sales (ss_item_sk, ss_quantity, ss_net_paid)
# TABLE item (i_item_sk, i_product_name, i_category)
# JOIN HINTS:
#   JOIN item ON ss_item_sk = i_item_sk
```

## ğŸ“Š Expected Results

| Method | Context Size | Accuracy (Easy Set) |
|--------|--------------|---------------------|
| Full Schema (24 tables) | ~8000 tokens | ~10-20% |
| Schema Linking (3-5 tables) | ~1200 tokens | **30-40%** (expected) |
| + Few-shot (3 examples) | ~1500 tokens | **40-50%** (expected) |

## ğŸ“ Research References

- **RESDSQL** (Schema linking with representation learning)
- **DAIL-SQL** (Example selection via embedding)
- **DIN-SQL** (Decomposition and self-correction)

## ğŸ”§ Troubleshooting

**Q: Schema linking khÃ´ng hoáº¡t Ä‘á»™ng?**
```bash
# Check dependencies
pip install sentence-transformers
python -c "from schema_linking import SchemaLinker; SchemaLinker()"
```

**Q: Accuracy váº«n tháº¥p?**
- Finetune láº¡i vá»›i `train_tpcds_linked.jsonl` (schema linking data)
- TÄƒng few-shot examples lÃªn 5-7
- Thá»­ model lá»›n hÆ¡n (7B/14B)

**Q: Training data cÃ³ bao nhiÃªu samples?**
```bash
wc -l research_pipeline/datasets/train_tpcds_linked.jsonl
```

## ğŸ“ Next Steps

1. **Generate training data**: `python generate_tpcds_training_data.py`
2. **Finetune model**: With `--train-data train_tpcds_linked.jsonl`
3. **Benchmark**: With `--schema-linking` flag
4. **Compare**: Full schema vs Linked schema vs Few-shot

## ğŸ“ Generated Files

```
research_pipeline/datasets/
â”œâ”€â”€ train_tpcds_linked.jsonl        # Training data with schema linking
â”œâ”€â”€ train_tpcds_full_schema.jsonl  # Training data with full schema (fallback)
â””â”€â”€ test_easy.csv                   # Test set (easier samples)
```
